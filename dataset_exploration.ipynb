{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = './data/dataset/disk_data.csv'\n",
    "cols = ['date', 'serial_number', 'model', 'failure', 'vault_id', 's9_power_on_hours']\n",
    "\n",
    "df = pd.read_csv(file_path, usecols=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print column names and theit NaN count\n",
    "def print_nan_count_per_column(df):\n",
    "    nan_count_per_column = df.isna().sum()\n",
    "    print(nan_count_per_column)\n",
    "\n",
    "def print_wrong_vault_id_count(df):\n",
    "    wrong_vault_id_count = df[df['vault_id'] == 'vault_id'].shape[0]\n",
    "    print('Wrong vault id count', wrong_vault_id_count)\n",
    "\n",
    "# Print column names and their data types\n",
    "def print_col_types(df):\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        print(f\"Column: {column}, Dtype: {dtype}\")\n",
    "\n",
    "def print_wrong_serial_count(df):\n",
    "    wrong_serial_count = df['serial_number'].str.contains('-').sum()\n",
    "    print('Wrong serial number count', wrong_serial_count)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wrong_vault_id_count(df)\n",
    "print_nan_count_per_column(df)\n",
    "print_col_types(df)\n",
    "print_wrong_serial_count(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0) #Drop row with NaNs\n",
    "df = df[~( df['vault_id'] == 'vault_id')] #Drop rows with 'vault_id' as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nan_count_per_column(df)\n",
    "print_wrong_vault_id_count\n",
    "print_col_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_convert_to_int(value):\n",
    "    try:\n",
    "        int(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        print('Cannot convert to int: ', value)\n",
    "        return False\n",
    "    \n",
    "# Column to check\n",
    "column_to_check = 'vault_id'\n",
    "\n",
    "# Check which elements of the column can be converted to int\n",
    "convertible_indices = [idx for idx, value in enumerate(df[column_to_check]) if can_convert_to_int(value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['serial_number'] = df['serial_number'].astype(str)\n",
    "df['model'] = df['model'].astype(str)\n",
    "df['failure'] = df['failure'].astype(bool)\n",
    "df['vault_id'] = df['vault_id'].astype(int)\n",
    "df['s9_power_on_hours'] = df['s9_power_on_hours'].astype(float)\n",
    "df['s9_power_on_hours'] = df['s9_power_on_hours'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_col_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "def is_parquet_file(file_path):\n",
    "    try:\n",
    "        # Try to read the Parquet file metadata\n",
    "        pq.read_metadata(file_path)\n",
    "        return True\n",
    "    except (pq.lib.ArrowIOError, ValueError):\n",
    "        # If an error is raised, it is not a Parquet file\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "file_path = '~/Desktop/disk_data.parquet'\n",
    "if is_parquet_file(file_path):\n",
    "    print(f\"{file_path} is a Parquet file.\")\n",
    "else:\n",
    "    print(f\"{file_path} is not a Parquet file.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "dfp = pd.read_parquet(file_path)\n",
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_col_types(dfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
